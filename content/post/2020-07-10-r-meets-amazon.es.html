---
title: "Automatizando la vida diaria: Amazon"
author: ''
date: '2020-07-10'
slug: r-meets-amazon
categories:
  - Post
tags:
  - R
  - RStats
  - NLP
images: []
authors: []
---



<p>Estoy convencido de que saber un lenguaje de programación puede ayudarte no solo en tu vida profesional y/o académica sino también en tu vida diaria, por ello he decidido empezar una serie llamada <em>Automatizando la vida diaria</em>, donde mostraré cómo automatizar algunos procesos cotidianos.</p>
<p>En este primer post enseñaré como obtener comentarios de productos de Amazon usando R para aplicarles un poco de <em>analytics</em> y así sacarles provecho a la hora de elegir un producto.</p>
<div id="motivación" class="section level3">
<h3>Motivación</h3>
<p>Como a muchos, me preocupa que al hacer compras por internet esté eligiendo el producto adecuado dado que no podré verlo sino hasta que me lo entreguen :grimacing:. Por ello cuando estoy en busca de un producto suelo pasar una buena parte de tiempo viendo/leyendo reseñas para asegurarme de hacer una buena elección pero a pesar del esfuerzo nunca podré leerlas todas y hay ocasiones en donde preferiría ocupar mi tiempo en algo más interesante que eso, honestamente sería mucho más fácil si alguien lo hiciera por mi :satisfied:.</p>
<p>Pues de esa necesidad e inspirado por <a href="https://martinctc.github.io/blog/vignette-scraping-amazon-reviews-in-r/">este post</a> se me ocurrío que el proceso de <em>análisis</em> de las opiniones de productos en Amazon bien puede automatizarse usando R.</p>
</div>
<div id="requisitos" class="section level3">
<h3>Requisitos</h3>
<p>Para el proceso de descarga de las opiniones usaremos las siguientes librerías.</p>
<ul>
<li><p><a href="https://github.com/tidyverse/rvest">{rvest}</a>: Este paquete es el que nos permitirá descargar información de páginas web.</p></li>
<li><p><a href="https://github.com/dmi3kno/polite">{polite}</a>: Con este paquete seremos educados al hacer <em>scrapping</em> para evitar romper ciertas reglas sobre el uso de bots en la navegación web.</p></li>
<li><p><a href="https://github.com/tidyverse/stringr">{stringr}</a>: Este lo usaremos para el proceso de limpieza.</p></li>
<li><p><a href="https://github.com/tidyverse/purrr">{purrr}</a>: Este no está directamente relacionado con la tarea de descarga de información pero nos ayudará en las funciones que crearemos.</p></li>
</ul>
<p>Y por supuesto usaremos <a href="https://www.amazon.com.mx/">Amazon</a> como el sitio para descargar las opiniones.</p>
<p>Adicionalmente, para análisis las opiniones extraídas usaremos el paquete {<a href="https://bnosac.github.io/udpipe/en/">udpipe</a>}.</p>
</div>
<div id="muy-breve-introducción-a-web-scrapping" class="section level3">
<h3>(Muy) Breve introducción a <em>web scrapping</em></h3>
<p>El termino <em>web scrapping</em> hace referencia a una técnica que permite extraer información de sitios web para <em>exportarla</em> a formatos que sean más amigables y/o útiles.</p>
<p>Generalmente esto significa que la información que necesitamos no está disponible en ningún archivo y el único lugar donde se encuentra es justamente la página web.</p>
<p>El proceso de extracción no suele ser sencillo dado que hay una gran cantidad de tipos de sitios web y sus respectivas configuraciones harán que el algoritmo de extracción varíe, sin embargo suele ser más fácil (y rápido) que extraer la información manualmente, i.e. CTRL+C &amp; CTRL+V.</p>
<p>Para poder hacer la extracción será necesario saber <em>dónde</em> está la información. Para simplificar las cosas pensemos que una página web funciona como un directorio de nuestra computadora, así que será necesario entender <em>en qué carpeta</em> está eso que queremos; para encontrarla usaremos las herramientas de desarrollador disponibles en algunos buscadores (en nuestro caso usaremos Google Chrome).</p>
<p>En Chrome será tan fácil cómo colocar el cursor sobre el contenido de interés, dar click derecho y luego dar click en <em>Inspect</em> o <em>Inspeccionar</em>.</p>
</div>
<div id="extrayendo-comentarios-de-amazon" class="section level3">
<h3>Extrayendo comentarios de Amazon</h3>
<p><strong>¿Dónde están los comentarios?</strong></p>
<p>Primero será pertienente mencionar que cada producto en Amazon viene con código único que lo identifica y que podemos encontrar en la URL del producto:</p>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/product_code.png" style="width:100.0%" /></p>
<p>Una vez identificado el código del producto podemos usarlo para buscar la opiniones de éste, si bien podemos encontrarlas en la misma <em>página</em> en la que estemos viendo el producto, será más fácil (para la automatización) usar la dirección: www.amazon.com.mx/product-reviews/“código_del_producto”. En nuestro ejemplo esta dirección se convierte en: <a href="https://www.amazon.com.mx/product-reviews/B08356LFM3">www.amazon.com.mx/product-reviews/B08356LFM3</a>.</p>
<p>Ahora sí, usando la herramienta de inspección de Chrome podemo identificar dónde están <em>guardados</em> los comentarios:</p>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/product_review.png" style="width:100.0%" /></p>
<p>Notemos además que si queremos ver otra página de opiniones la dirección quedaría construída como sigue: <a href="https://www.amazon.com.mx/product-reviews/B08356LFM3/?pageNumber=2" class="uri">https://www.amazon.com.mx/product-reviews/B08356LFM3/?pageNumber=2</a></p>
</div>
<div id="automatizando-la-extracción" class="section level3">
<h3>Automatizando la extracción</h3>
<p>Una vez entendido (más o menos) de dónde obtener la información podemos crear las funciones necesarias para automatizar la extracción.</p>
<p>La primera función será la que justamente hará el trabajo de extracción:</p>
<pre class="r"><code>get_reviews &lt;- function(id, pages){
  
  webpage &lt;- paste0(&quot;https://www.amazon.com.mx/product-reviews/&quot;, id)
  session &lt;- bow(webpage)
  
  reviews_list &lt;- map(1:pages, ~scrape(session, query = list(pageNumber = .x)) %&gt;% 
                              html_nodes(&quot;[class=&#39;a-size-base review-text review-text-content&#39;]&quot;) %&gt;% 
                              html_text())
  
  reviews &lt;- clean_reviews(unlist(reviews_list))
  
  return(reviews)

}</code></pre>
<p>Notemos que adicionalmente estamos usando una función que nos permite limpiar las opiniones extraídas y que está definida como sigue:</p>
<pre class="r"><code>clean_reviews &lt;- function(reviews){
  
  cleaned &lt;- str_replace_all(reviews, &quot;[\r\n]&quot;, &quot;&quot;) %&gt;% 
    str_replace_all(., &quot;[.]&quot;, &quot; &quot;) %&gt;% 
    str_replace_all(., &quot;[,]&quot;, &quot; &quot;) %&gt;% 
    str_replace_all(., &quot;[;]&quot;, &quot; &quot;) %&gt;% 
    str_replace_all(., &quot;[\&quot;]&quot;, &quot; &quot;) %&gt;% 
    tolower() %&gt;% 
    trimws() %&gt;% 
    paste(collapse = &quot; &quot;)
  
  return(cleaned)
  
}</code></pre>
<p>N.B. Esta función de limpieza la cree después de hacer una primera descarga.</p>
<p>Y listo, en realidad esas son las funciones esenciales que necesitamos para extraer los comentarios :sweat_smile:.</p>
<p>Para extraer comentarios de e.g. <a href="https://www.amazon.com.mx/Samsung-LC24F390FHLXZX-Monitor-Curvo-Glossy/dp/B01IDNQDSS/ref=cm_cr_arp_d_product_top?ie=UTF8">este producto</a> correremos lo siguiente:</p>
<pre class="r"><code>opiniones &lt;- get_reviews(&quot;B01IDNQDSS&quot;, 10)</code></pre>
<p>El objeto <code>opiniones</code> será un vector de un elemento en el cuál estarán las opiniones de 10 páginas.</p>
<p>Ahora que ya tenemos esto descargado podemos aplicarles un poco de <em>analytics</em> para analizarlos.</p>
</div>
<div id="analizando-los-comentarios" class="section level3">
<h3>Analizando los comentarios</h3>
<p>El análisis más sencillo que se puede aplicar es crear nubes de palabras sin embargo éstas no son muy informativas pues solo consisten de frecuencias.</p>
<p>En lugar de ello lo que haremos será:</p>
<ol style="list-style-type: decimal">
<li><p>Identificar los adjetivos com mayor ocurrencia en las opiniones.</p></li>
<li><p>Extraer las palabras/frases clave en ellas</p></li>
</ol>
<p>Como lo mencionabamos anteriormente, para estas tareas usaremos la librería {<code>udpipe</code>}, la cual nos permitirá aplicar técnicas de procesamiento de lenguaje natural como <em>tokenización</em> y <em>lematización</em>.</p>
<p>Lo primero que haremos será cargar el modelo pre-entrenado para el idioma español:</p>
<pre class="r"><code># udpipe_download_model(language = &quot;spanish-gsd&quot;)
model &lt;- udpipe_load_model(&quot;spanish-gsd-ud-2.4-190531.udpipe&quot;)</code></pre>
<p>Ahora, le aplicaremos el modelo a nuestras opiniones:</p>
<pre class="r"><code>x &lt;- udpipe_annotate(model, opiniones)
x &lt;- as.data.frame(x, detailed = TRUE)</code></pre>
<p>Básicamente lo que esto hace es tomar cada palabra del vector de opiniones y evaluar si ésta es un verbo, adjetivo, adverbio, sustantivo, etc.</p>
<p>También lematiza cada palabra, es decir, encuentra su palabra representante, por ejemplo para las palabras [caminando, caminé, caminaba] su representante o lema será [caminar].</p>
<p>E incluso el modelo identifica características morfológicas de la palabra como el género, las formas personales (en el caso de los verbos) o si se está usando de forma singular o plural.</p>
<table>
<thead>
<tr class="header">
<th align="left">token</th>
<th align="left">lemma</th>
<th align="left">upos</th>
<th align="left">xpos</th>
<th align="left">feats</th>
<th align="left">head_token_id</th>
<th align="left">dep_rel</th>
<th align="left">deps</th>
<th align="left">misc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">soy</td>
<td align="left">ser</td>
<td align="left">AUX</td>
<td align="left">NA</td>
<td align="left">Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin</td>
<td align="left">2</td>
<td align="left">cop</td>
<td align="left">NA</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">estudiante</td>
<td align="left">estudiante</td>
<td align="left">NOUN</td>
<td align="left">NA</td>
<td align="left">Number=Sing</td>
<td align="left">16</td>
<td align="left">nsubj</td>
<td align="left">NA</td>
<td align="left">NA</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="left">y</td>
<td align="left">CCONJ</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">4</td>
<td align="left">cc</td>
<td align="left">NA</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">paso</td>
<td align="left">paso</td>
<td align="left">NOUN</td>
<td align="left">NA</td>
<td align="left">Gender=Masc|Number=Sing</td>
<td align="left">2</td>
<td align="left">conj</td>
<td align="left">NA</td>
<td align="left">NA</td>
</tr>
<tr class="odd">
<td align="left">más</td>
<td align="left">más</td>
<td align="left">ADV</td>
<td align="left">NA</td>
<td align="left">Degree=Cmp</td>
<td align="left">7</td>
<td align="left">advmod</td>
<td align="left">NA</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">de</td>
<td align="left">ADP</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">5</td>
<td align="left">case</td>
<td align="left">NA</td>
<td align="left">NA</td>
</tr>
</tbody>
</table>
<p>Con toda esta información podemos explorar fácilmente los adjetivos más frecuentes dentro de las opiniones:</p>
<pre class="r"><code>adj_stats &lt;- x %&gt;% 
  dplyr::filter(upos == &quot;ADJ&quot;)

adj_stats &lt;- txt_freq(adj_stats$lemma)

ggplot(head(adj_stats, 20), aes(reorder(key, freq_pct), freq_pct))+
  geom_point()+
  geom_linerange(aes(ymin = 0, ymax = freq_pct))+
  labs(x = &quot;&quot;, y = &quot;Frecuencia (%)&quot;)+
  ggtitle(&quot;Adjetivos&quot;)+
  coord_flip()+
  theme_minimal()</code></pre>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/figure-html/unnamed-chunk-8-1.png" width="768" /></p>
<p>Que también podemos graficar como nube de palabras gracias {<a href="https://github.com/lepennec/ggwordcloud"><code>ggwordcloud</code></a>}</p>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/figure-html/unnamed-chunk-9-1.png" width="768" /></p>
<p>O las palabras/frases clave:</p>
<pre class="r"><code>rake_stats &lt;- keywords_rake(x, term = &quot;lemma&quot;, group = &quot;doc_id&quot;, relevant = x$upos %in% c(&quot;NOUN&quot;, &quot;ADJ&quot;))

ggplot(head(rake_stats, 20), aes(reorder(keyword, rake), rake))+
  geom_point()+
  geom_linerange(aes(ymin = 0, ymax = rake))+
  coord_flip()+
  theme_minimal()</code></pre>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/figure-html/unnamed-chunk-11-1.png" width="768" /></p>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/figure-html/unnamed-chunk-12-1.png" width="768" /></p>
<p>*Para las palabras/frases clave se utiliza un algorítmo de identificación llamado RAKE.</p>
</div>
<div id="reflexiones" class="section level3">
<h3>Reflexiones</h3>
<p>La automatización creada para analizar los comentarios nos permite determinar que el producto en el que estamos interesados es evaluado como bueno y excelente.</p>
<p>Además podemos indentificar rápidamente que los <em>temas</em> más relevante en las opiniones son que el producto resultó una buena inversión, una buena compra y de buena calidad, por mencionar algunos.</p>
<p>Y no tuvimos que leer ninguno de los comentarios contenidos en 10 páginas :sunglasses:.</p>
<p>Por supuesto que el análisis puede ir más allá de lo que aquí mostramos, podríamos por ejemplo evaluar el sentimiento de los comentarios para fácilmente detectar si se habla de forma positiva o negativa del producto. También podrías extraer la cantidad de estrellas para tener un resumen visual rápido, etc.</p>
</div>
<div id="automatización-completa" class="section level3">
<h3>Automatización completa</h3>
<p>A pesar de que hemos logrado automatizar de buena manera el proceso de análisis de opiniones de Amazon aún tenemos que correr manualmente el código y si queremos compartir con alguien esta automatización, esa persona tendría que saber R.</p>
<p>Para no depender de tener que correr el código o estar limitado para compartirlo, he creado <a href="https://davidalbertofciencias.shinyapps.io/amzreviewer/">esta app</a> que no solamente nos evitará la tarea de correr el código sino que además nos permitirá compartir estas herramientas con muchas más personas (y quiza pueda ayudarles a hacerles la vida más sencilla).</p>
<p>Únicamente hay que darle a la app la URL del producto en el que estamos interesados y listo. Incluso agregué una opción para cambiar el sitio entre Amazon México y Amazon US :wink:.</p>
<p>Nota: La app está limitada a extraer 5 páginas de comentarios dado que el proceso es algo tardado si no quieres tener esa limitante lo mejor es <a href="">instalar el paquete</a> directamente en tu computadora.</p>
<p><img src="/post/2020-07-10-r-meets-amazon.es_files/amazon_reviews.gif" style="width:100.0%" /></p>
</div>
